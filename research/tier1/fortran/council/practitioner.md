# Fortran — Practitioner Perspective

```yaml
role: practitioner
language: "Fortran"
agent: "claude-sonnet-4-6"
date: "2026-02-28"
schema_version: "1.1"
```

---

## 1. Identity and Intent

Fortran is not a language most practitioners choose. It is a language they inherit, or that chooses them by virtue of their field. If you take a job modeling atmospheric dynamics at a national weather center, writing seismic processing code at an oil company, or maintaining legacy structural analysis software at an aerospace firm, Fortran is waiting for you. That is the practitioner's first honest accounting of Fortran's identity in 2026: for better and worse, it is a language of necessity and domain lock-in rather than one of voluntary selection.

That necessity, however, is neither random nor arbitrary. Fortran's monopoly on certain high-performance numerical domains persists because it earned it. The original bet Backus and his team made — that a compiled high-level language could match hand-assembled machine code for numerical work — was vindicated almost immediately [IBM-HISTORY-FORTRAN], and it has never fully been overturned. The practitioner who works in numerical weather prediction encounters codebases like the ECMWF Integrated Forecasting System, where a Fortran kernel that runs on thousands of processor cores, consuming millions of CPU-hours per day, is too correct, too tuned, and too validated to replace with anything else [WRF-FORTRAN-MEDIUM]. The domain dependency is not nostalgia — it is economic rationality about validated scientific software.

The honest version of Fortran's identity fractures into two very different languages that share a name. The first is **FORTRAN 77 and legacy code**: fixed-form source with its six-character identifier limit, columns 7–72, implicit typing, COMMON blocks, EQUIVALENCE, GOTO-driven control flow. This code exists in enormous quantity across national laboratories, climate centers, aerospace organizations, and academic institutions, and a substantial fraction of working Fortran practitioners spend most of their time reading, debugging, and cautiously extending it. The second is **modern Fortran** (Fortran 90 onward, with Fortran 2003+ for OOP and C interop): free-form source, modules, allocatable arrays, type-bound procedures, ISO_C_BINDING, coarrays, DO CONCURRENT. Modern Fortran is a genuinely capable systems programming language for scientific computing, and the fortran-lang community that formed around 2020 has been building the tooling to match [ARXIV-TOOLING-2021].

The practitioner lives in both worlds simultaneously, and the collision between them is the defining tension of actually writing Fortran in production. A team writing new modern Fortran calls routines from legacy code that still uses COMMON blocks. The module interfaces are clean; the implementation underneath reaches into shared global state from 1985. You trace a numerical result backward through a call stack and eventually land in a FORTRAN 77 subroutine named things like `COMPFU` that processes global arrays via EQUIVALENCE with multiple aliased names. This is the production reality that no language specification and no benchmark suite captures.

---

## 2. Type System

The first thing a practitioner learns about Fortran's type system is the thing that should not need learning: **put `IMPLICIT NONE` at the top of every compilation unit**. Without it, any undeclared variable whose name begins with I through N defaults to INTEGER; everything else defaults to REAL. This is not a historical curiosity — it is a live footgun in any legacy code you read or extend, and it is responsible for an entire category of silent numerical bugs where a typo in a variable name creates a fresh implicit variable rather than producing a compilation error [RESEARCH-BRIEF-TECH]. Modern style guides, fortran-lang best practices, and every Fortran textbook written after 1990 are unanimous: `IMPLICIT NONE` always. The fact that the language still allows implicit typing without it — that suppressing a decades-known footgun requires an opt-in declaration — is itself a lesson in how backward compatibility imposes costs that compound over time.

Once you establish `IMPLICIT NONE`, Fortran's type system for numerical work is a genuine strength. The KIND parameter system for selecting precision at the type level is more explicit and less error-prone than C's platform-dependent `int` and `long` sizes. Using `use iso_fortran_env, only: real64, int32` and declaring `real(kind=real64)` makes precision choices explicit and portable, which matters in code that runs on everything from laptops to exascale systems with different word lengths [ISO-FORTRAN-2023]. C practitioners moving to Fortran often find this refreshing — no more wondering whether `double` is 64 bits on this particular compiler and platform.

The array type system is Fortran's most distinctive practical contribution. Arrays are not pointers to memory blocks — they are first-class typed objects with rank and bounds known at compile time or carried at runtime in array descriptors. This enables whole-array arithmetic that the compiler understands at the type level: `A = B + C` for 3D arrays is a type-correct expression that compiles to vectorized loops, not a pointer operation that the programmer must manually loop over. Intrinsic functions like `MATMUL`, `DOT_PRODUCT`, `SUM`, `MAXVAL`, and `TRANSPOSE` are part of the language, not a library, and they compose with array sections (`A(1:n:2, 3:m)`) that express strided access patterns in a single expression [FORTRAN-LANG-DERIVED]. After using this in production, returning to C's flat arrays and manual indexing arithmetic genuinely feels like a regression.

The failures of the type system become apparent in more complex programming situations. Fortran has no algebraic data types, no sum types, no Result/Option equivalents. A subroutine that can return a valid array or an error cannot express that in the type system — it returns the array and an integer status code, and the caller may or may not check the status code. Fortran has no mechanism analogous to Rust's `must_use` to enforce that callers handle error conditions. In practice, legacy codebases are full of unchecked STAT return values from ALLOCATE calls, unchecked IOSTAT from file operations, and unchecked return codes from numerical routines. The type system cannot help you catch this class of bug.

Generics are the permanent missing feature. Fortran achieves generic behavior through **generic interfaces** — multiple type-specific implementations registered under one interface name — which means library authors write separate `REAL32`, `REAL64`, and sometimes `COMPLEX64`, `COMPLEX128` versions of every routine and maintain them as a set. The fortran-lang/stdlib project, for instance, maintains kind-parameterized implementations of sorting, hashing, and statistical functions by code generation or preprocessor tricks rather than language-level parametric polymorphism [STDLIB-GITHUB]. This is manageable but inelegant, and it means the practitioner browsing a library's source sees three or four implementations where one generic implementation would exist in Rust or C++. Templates/generics are in discussion for the post-2023 standard [J3-HOME], but they have not arrived.

**`CLASS(*)`** (unlimited polymorphism, Fortran 2003) exists and allows writing containers that accept any type, but at the cost of losing static dispatch — you get `CLASS(*)` dummy arguments and then must use `SELECT TYPE` to recover the concrete type. This pattern is functional but verbose and produces code that feels like writing `instanceof` chains in Java circa 2005. In production, most practitioners restrict their OOP usage to the narrower type-extension (`EXTENDS`) pattern for concrete type hierarchies and avoid `CLASS(*)` containers unless genuinely necessary.

---

## 3. Memory Model

Fortran's practical memory story divides cleanly into what allocatable arrays give you and what everything else takes away.

**Allocatable arrays** are the right abstraction for the vast majority of dynamically-sized numerical data in production Fortran code. They automatically deallocate when the containing scope exits, they are always contiguous in memory (enabling vectorization and cache-friendly access), and failure to allocate is detectable via the `STAT=` argument to `ALLOCATE`. In practice, a well-written modern Fortran codebase that uses allocatables throughout will have a clean memory model: no leaks from the allocatable machinery itself, cache-efficient access patterns, and no dangling pointers from the allocatable mechanism [FORTRAN-LANG-ALLOC]. For scientific computing — where the canonical data structure is a large multidimensional array of floating-point values — this is often all you need.

The practitioner's frustration emerges from the gaps. First: **STAT checking is optional and frequently omitted**. When a 3D atmospheric model fails to allocate a 2000×3000×100 `REAL64` array because the node ran out of memory, the correct response is a clean error message and controlled shutdown. The actual response, in codebases that skip `STAT=ierr`, is a runtime abort with a cryptic message about allocation failure from the Fortran runtime, a process dump, and a job scheduler that marks the node as failed. The language permits not checking STAT; the specification does not require compilers to produce useful diagnostics on unhandled allocation failures; and most legacy code was not written to check STAT. This is not a problem with the allocatable mechanism — it is a problem with the error-handling integration around it.

**Fortran pointers** are a more serious story. They are necessary for aliasing (pointing into sub-arrays or existing data structures), for linked structures, and for callback function pointers. They are also the primary memory hazard in Fortran that the allocatable mechanism does not protect against. A `POINTER` variable's status is **undefined** at declaration — you must explicitly `NULLIFY` it before testing `ASSOCIATED()`, but the compiler does not enforce this [RESEARCH-BRIEF-TECH]. Pointer-based memory is not automatically deallocated at scope exit. A subroutine that allocates through a pointer and returns without deallocating creates a memory leak that neither the language nor the compiler (by default) will flag. In legacy codes that used Fortran 90 pointers extensively before allocatables became idiomatic, pointer-induced memory leaks are a real operational concern on long-running simulations.

**Column-major ordering** is a constant cognitive load and a consistent source of bugs at language boundaries. Fortran stores `A(i,j)` with i varying fastest (column-major), the opposite of C and Python (row-major). For purely in-Fortran code iterating correctly (inner loop over first index), this is a performance advantage — consecutive memory access patterns match cache line loading. At the C interoperability boundary, it is a persistent footgun. When a Fortran array is passed to a C function that treats it as row-major (or vice versa), the data appears transposed, producing numerically wrong results without any type error or runtime exception. This bug is particularly insidious because the code compiles cleanly, the values are not obviously wrong (they are valid floating-point numbers), and the error may only manifest as subtle numerical divergence rather than a crash. Every practitioner who has worked at the Fortran/C boundary has hit this.

The **COMMON block and EQUIVALENCE** legacy in inherited code is the worst part of the memory model story. COMMON blocks create shared global storage between compilation units with no type checking — COMMON `/WORK/ A, B, C` in one file and `COMMON /WORK/ X, Y, Z` in another might have different sizes or types with no compilation error and undefined behavior [RESEARCH-BRIEF-TECH]. EQUIVALENCE overlaps the storage of two variables, allowing INTEGER and REAL access to the same memory location. These features were officially removed from the Fortran 2023 standard but compilers continue to support them, and they exist in enormous quantities of production code. When a numerical result is wrong and you trace the error into a routine that uses COMMON blocks, you are debugging a form of global aliasing that has no parallel in modern languages and that static analysis tools struggle to reason about.

---

## 4. Concurrency and Parallelism

The practitioner's honest assessment of Fortran's parallel programming landscape is: **MPI is the reality; everything else is a qualifier**. Coarrays, OpenMP, OpenACC, and DO CONCURRENT all have their places, but the dominant paradigm for distributed HPC in 2026 remains MPI — a library, not a language feature, which has been the workhorse of large-scale scientific computing for over thirty years [RESEARCH-BRIEF-TECH]. The most production-hardened, most widely deployed, most extensively debugged parallel Fortran code uses MPI. That this is a library rather than a language feature says something important about Fortran's parallelism story.

**OpenMP** is the closest to a practical shared-memory success. Supported consistently by GFortran, Intel ifx, and NVIDIA nvfortran, OpenMP directives for thread parallelism work in production and the tooling for diagnosing race conditions (Intel Inspector, thread sanitizer) is mature. The `!$OMP PARALLEL DO` pattern for loop parallelization is well-understood, extensively documented, and has decades of production experience behind it. The practitioner can add OpenMP to a serial code incrementally, profile, confirm scaling, and trust the result. This is genuinely functional.

**Coarrays** tell a different story. They were standardized in Fortran 2008 and significantly extended in Fortran 2018 [COARRAYS-SOURCEFORGE], but compiler support for the full Fortran 2018 coarray specification was still maturing as of 2024. Intel ifx has the most complete implementation [INTEL-COARRAY], GFortran's coarray support relies on the OpenCoarrays library for distributed execution (single-image execution compiles natively; multi-image requires the library), and LLVM Flang's coarray support is incomplete as of early 2026. The practitioner who wants to write new coarray-based code in 2026 faces a choice: use Intel ifx and accept platform lock-in on Intel-compatible hardware, use GFortran + OpenCoarrays and accept the library dependency and its performance overhead, or avoid coarrays and use MPI instead. Most teams making new development choices choose MPI. Coarrays are an elegant native parallelism model that the ecosystem has not yet made fully practical at scale.

**DO CONCURRENT** (Fortran 2008+, enhanced in 2023) is increasingly useful but inconsistently exploited. It tells the compiler that loop iterations have no data dependencies, enabling vectorization and potentially parallelization. In practice, `gfortran` reliably vectorizes well-structured DO CONCURRENT loops; NVIDIA nvfortran can compile DO CONCURRENT loops to GPU code with `-stdpar=gpu` [NVIDIA-DO-CONCURRENT]; and the Fortran 2023 REDUCTION clause enables reduction operations in concurrent loops. The practitioner value is real but conditional: DO CONCURRENT works when the compiler takes advantage of it, and the extent of parallelization varies significantly by compiler, optimization level, and loop structure. You cannot write DO CONCURRENT and assume all compilers on all systems will exploit it equally. For GPU execution specifically, NVIDIA's support is meaningfully ahead of other compilers.

**GPU programming** in Fortran is a three-way split: OpenACC (NVIDIA-specific, mature, effective for NVIDIA hardware), OpenMP target offload (more portable, supported by Intel ifx for Intel GPUs and NVIDIA nvfortran), and CUDA Fortran (NVIDIA-proprietary, maximally expressive for NVIDIA GPUs). The weather and climate community has extensively ported codes like WRF to OpenACC [NVIDIA-HPC-SDK], and NVIDIA reports meaningful speedups. But the practitioner's frustration is that GPU Fortran is not write-once-run-anywhere: OpenACC code runs well on NVIDIA; Intel GPUs use OpenMP offload; AMD support in Flang is emerging but not yet at production maturity as of early 2026. The supercomputer your code runs on determines which GPU programming model you use, and changing supercomputers may require significant code changes.

The fundamental structural issue: Fortran's concurrency model is coarse-grained (MPI processes, OpenMP threads, coarray images, GPU kernels) with no native support for fine-grained async/await, task-based parallelism, or structured concurrency. This matches HPC's actual programming model — you do not write a web server in Fortran — but it means there is no good story for mixed workloads that require both large-scale distributed parallelism and fine-grained concurrent I/O or event handling. For its intended domain, this is acceptable.

---

## 5. Error Handling

Fortran's error handling is the practical weakest link for production systems, not because the mechanisms are unavailable, but because they are optional, inconsistent, and almost universally underused in production code.

The primary mechanism for I/O errors is the `IOSTAT=` specifier: attach an integer variable to any READ or WRITE, check it afterward, branch on nonzero. For allocation failures, `STAT=ierr` on `ALLOCATE` serves the same purpose. These mechanisms work and are well-specified [FORTRAN-WIKIBOOKS-ERR]. The problem is the gap between "available" and "used." In production legacy codebases, the pattern is overwhelmingly:

```fortran
WRITE(10, '(F10.4)') value
READ(5, *) temperature
CALL decompose(matrix, n, info)
```

Without IOSTAT, without STAT, without checking `info`. If the file handle is invalid, if the disk is full, if the allocation fails, if the decomposition fails to converge — the program continues with undefined state or aborts ungracefully. The practitioner debugging a production HPC job that silently produced wrong results for twelve hours before the job scheduler killed it for exceeding its time allocation must trace through code with essentially no error instrumentation.

The deeper problem is **propagation**. Even when a subroutine properly checks its errors and returns a status code, propagating that status through a deep call stack requires passing integer error parameters through every intermediate routine. Fortran has no exceptions, no Result types, no monadic error propagation. The pattern that careful Fortran code uses — `INTENT(OUT) ierr` on every subroutine — requires every intermediate caller to (a) declare the `ierr` variable, (b) pass it through, (c) check it, and (d) return early or continue with partial error information. This is the pattern C used before it had better options, and it has the same defects: error status is easily dropped, intermediate functions must be modified to thread errors through, and the signature of every function accumulates error-handling cruft. The `errstat` library [ERRSTAT-GITHUB] provides enhanced error-status derived types, but it is not part of the standard and not used in most code.

**IEEE exception handling** (Fortran 2003's `IEEE_ARITHMETIC`, `IEEE_EXCEPTIONS`, `IEEE_FEATURES` modules) is the exception — pun intended — where Fortran's error handling actually works well for its core domain. Trapping divide-by-zero, overflow, and invalid operations via IEEE exception flags, checking them after intensive numerical kernels, is a production-useful pattern for numerical code that needs to detect the difference between a converged result and a silent NaN propagation [RESEARCH-BRIEF-TECH]. The practitioner who uses IEEE exception trapping properly can catch an entire class of numerical errors that would otherwise produce plausible-looking but wrong outputs. That almost no one outside of numerically rigorous HPC centers actually uses it is a DX failure, not a language specification failure.

The legacy `ERR=` branch syntax (`READ(5, *, ERR=100) value ... 100 CONTINUE`) is a GOTO-based error handling pattern that still appears in code written before IOSTAT became standard practice. Reading code with ERR= branches requires understanding non-local control flow that the language only partially structures. Encountering this in a 10,000-line module at 2 AM is the kind of experience that makes practitioners understand viscerally why structured exception handling was invented.

---

## 6. Ecosystem and Tooling

The 2021 paper "Toward Modern Fortran Tooling and a Thriving Developer Community" [ARXIV-TOOLING-2021] identified the gap bluntly: Fortran lacked a single recommended build system, a community-maintained standard library, general-purpose programming facilities, and meaningful modern tooling presence. That paper helped motivate the fortran-lang.org initiative that has since produced fpm, stdlib, and fortls. The practitioner's question is: how far has that closed the gap, and where does it still bite?

**The build system story** has improved significantly. Before fpm, starting a new Fortran project meant choosing between Autotools (capable but arcane), CMake (necessary for large projects, Fortran-specific pain), custom Makefiles (proliferating and incompatible), or cobbling together something from scratch. This "set up a new project" friction was a real barrier that discouraged experimentation and made small-scale Fortran programming unnecessarily heavy. `fpm` [FPM-HOME] addresses this: `fpm new myproject` creates a working scaffold, `fpm build` compiles it, `fpm run` executes it. The model is clearly inspired by Cargo, and for new projects it is a genuine improvement. Version 0.13.0 (2024) added build profiles and conditional compilation [FPM-2024].

But fpm does not yet cover the large HPC projects that dominate real production Fortran. WRF, CESM, VASP, Quantum ESPRESSO — these are CMake or Makefile projects with complex dependency chains, MPI integrations, and performance-critical compiler flag management. CMake's Fortran support is functional but has well-known rough edges: module dependency tracking is fragile in CMake, where Fortran's `.mod` files create implicit dependencies that CMake must discover at configuration time and may get wrong on incremental rebuilds. The practitioner who changes a module interface and gets subtle link errors rather than a full recompilation has experienced CMake's Fortran module dependency handling at its worst.

**The package ecosystem** is the starkest gap. PyPI has 550,000+ packages. npm has 2 million. The fortran-lang packages index lists dozens. The practitioner who needs JSON parsing, HTTP requests, data serialization, date-time handling, logging, or virtually any general-purpose functionality must either call C libraries via ISO_C_BINDING or write it themselves. The fortran-lang/stdlib project is filling some gaps (hash maps, sorting, strings, statistics) [STDLIB-GITHUB], but it is a community volunteer effort that has reached 1,000 stars on GitHub [STDLIB-1000-STARS] and a scope that, by any comparison with Python's standard library, remains thin. The consequence: production Fortran code that needs anything beyond numerical computation typically ends up as a thin Fortran wrapper around C libraries, with ISO_C_BINDING serving as the adhesive layer. This works but it means Fortran's effective ecosystem is C's ecosystem with a Fortran interface — a very different value proposition from "Fortran does everything natively."

**IDE and language server support** has improved meaningfully. The Modern Fortran extension for VS Code, backed by the `fortls` language server [VSCODE-FORTRAN], provides syntax highlighting, Go-to-definition, autocompletion from module interfaces, real-time error feedback from compiler integration, and debugger support. For new code developed in VS Code, this is a functional development environment. The honest comparison to Python (with Pylance/pyright providing essentially instant, complete type inference feedback) or Rust (with rust-analyzer providing deep semantic understanding) is unfavorable: fortls can navigate module interfaces but does not understand complex template patterns or provide the same depth of refactoring support. Intel Visual Studio integration on Windows is more capable for users in that environment [INTEL-IFX-2025].

**Testing** is functional but not ergonomic. The test-drive framework integrates with fpm and provides a workable unit testing story for new projects [FPM-HOME]. pFUnit supports NASA-grade parallel unit testing including MPI testing [NASA-FORTRAN-2015]. What is genuinely difficult is testing numerical correctness in inherited code: there are no mock frameworks, no fixtures, no dependency injection patterns, no standard way to intercept subroutine calls for testing. Testing a subroutine in a legacy codebase that uses COMMON blocks for shared state requires either modifying the subroutine to break the COMMON dependency (risky in production code) or setting up the entire COMMON block state correctly (fragile and slow). Integration testing is the only practical option for much legacy code, which means test suites that run the full model and check outputs rather than isolating units.

**AI tool support** is the emerging gap that the community is beginning to feel. GitHub Copilot, Claude, and ChatGPT all support Fortran at a basic level — they can write syntactically correct modern Fortran and explain the meaning of legacy code. But AI code assistance is proportional to training data density, and Fortran's corpus is thin compared to Python or JavaScript [RESEARCH-BRIEF-TECH]. Copilot suggestions for Fortran are noticeably less contextually appropriate than for mainstream languages; hallucinated intrinsic names appear; module interface completion is weaker. The community has discussed AI-assisted FORTRAN 77 → modern Fortran modernization as a use case, which is promising, but the current tools are not yet reliable enough for unreviewed automated modernization.

---

## 7. Security Profile

Fortran's security profile is unusual because most Fortran programs are simply not in the threat model for most security researchers. A numerical weather prediction model running on a closed HPC cluster, receiving input from authenticated scientific data feeds, is not an internet-facing service with an attack surface [RESEARCH-BRIEF-SECURITY]. The CVE database has minimal Fortran-language entries, and those that exist are predominantly compiler installer privilege escalation vulnerabilities (CVE-2024-28881, CVE-2022-38136) rather than vulnerabilities in Fortran applications [RESEARCH-BRIEF-SECURITY]. For the practitioner working at ECMWF or NASA, security is largely an access-control and institutional concern rather than a code-level concern.

Where the security picture is less comfortable is the memory-safety baseline. Fortran is classified as memory-unsafe under CISA/NSA guidelines [MEMORY-SAFETY-WIKI], and the classification is warranted: array out-of-bounds access without bounds checking produces undefined behavior, exactly as in C. The default in production builds is **no bounds checking** — enabling it (`-fcheck=bounds` in gfortran, `-check bounds` in ifx) adds runtime overhead that HPC practitioners consider unacceptable in tuned production runs, so it is enabled during testing and disabled in production [FORTRAN-DISCOURSE-BOUNDS]. This means the gap between "what I tested" and "what runs in production" includes a class of memory access bugs that are covered in test but exposed in production at full-scale runs.

The practical risk, given Fortran's deployment context, is primarily **silent wrong results from out-of-bounds access** rather than code execution vulnerabilities. A loop index error that reads beyond an array in a climate simulation produces wrong temperatures in the next timestep's calculation, not a remote code execution vulnerability. The Phrack article on Fortran memory corruption [PHRACK-FORTRAN] shows that exploitation is possible given specific access conditions, but the operational reality is that attacking a Fortran simulation code is not a threat most adversaries prioritize. The security concern is more about data integrity and scientific reproducibility than about information-security threat models.

The legacy **COMMON block and EQUIVALENCE** features add a type-aliasing vulnerability specific to older code: accessing the same memory location under different types can produce unexpected values that interact badly with the rest of the program's numerical state. This is not an external attack surface — it is an internal correctness hazard. But in a security-conscious context (a government agency running classified numerical simulations, for instance), the inability to guarantee memory type safety in the portions of code that use COMMON/EQUIVALENCE is a real architectural concern.

**Supply chain risk** in Fortran is genuinely low, primarily because the ecosystem is small and lacks the automated dependency resolution that makes npm and PyPI supply chains so broad and so vulnerable. The fpm registry is nascent and has limited attack surface [RESEARCH-BRIEF-SECURITY]. The practical worry is more about institutional code — research codes distributed as password-protected tarballs from university servers, lacking checksums and signed releases — than about sophisticated supply chain attacks. But that institutional distribution pattern is a different kind of risk: untracked dependencies, no audit trail, and no mechanism for applying security patches to downstream users.

---

## 8. Developer Experience

Measuring developer experience for Fortran requires acknowledging that Fortran has two completely distinct developer populations: **domain scientists** (physicists, atmospheric scientists, structural engineers) who write Fortran because their field requires it and who did not set out to be software developers, and **dedicated scientific software engineers** who have chosen software engineering in HPC as a profession. These populations have different experiences and different complaints.

For the domain scientist, Fortran's most important DX property is that **the numerical idioms feel natural**. Writing `A = B + C * D` for matrices, iterating with `do i = 1, n` and `do j = 1, m`, expressing a physical formula in notation close to the textbook derivation — this is what Fortran was designed for, and it delivers. The physicist who wants to implement a finite-difference scheme for heat diffusion writes Fortran code that looks much like the mathematical description of the scheme. Compared to C (where the same loop requires pointer arithmetic and explicit dimensionality management) or Python (where performance requires NumPy, which has its own idioms), Fortran's expressiveness for this use case is genuine.

The domain scientist's DX failures are equally clear: **getting started is still harder than it should be**, error messages are often opaque, and the gap between a working prototype and a production-quality code is large and poorly signposted. "Fortran" searching on Stack Overflow returns thin results compared to Python. The community forum at fortran-lang.discourse.group is active and responsive [FORTRAN-DISCOURSE], but it has hundreds of members, not millions. When you hit a problem at 2 AM and the options are Stack Overflow (weak Fortran coverage), a Discourse forum (slow response), or the man pages of a compiler (comprehensive but dense), the experience is materially worse than Python or Java.

For the **dedicated scientific software engineer**, the DX story is more nuanced. The tooling has improved dramatically since 2020: fpm, fortls, VS Code integration, and better compiler diagnostics make routine development substantially more pleasant. The fundamental DX pain is the **legacy code problem**: spending significant fractions of work time reading and maintaining FORTRAN 77 code that uses implicit typing, COMMON blocks, six-character identifiers, and fixed-form source is cognitively exhausting in a way that has no parallel in other modern production environments. There is no automated migration path; no compiler can tell you what a 30-year-old COMMON block is logically meant to represent; no refactoring tool can rename a six-character variable name to something descriptive while preserving all the implicit dependencies. This is artisanal archaeological work masquerading as software engineering.

**Onboarding** a new team member to a Fortran codebase in 2026 takes longer than onboarding to a Python or Java codebase of comparable complexity, for reasons both intrinsic and extrinsic. The intrinsic reasons: understanding column-major array storage and its implications, learning to read FORTRAN 77 code that looks nothing like the modern Fortran in textbooks, building intuition for the memory model (ALLOCATABLE vs. POINTER vs. COMMON). The extrinsic reasons: fewer tutorials, thinner Stack Overflow coverage, no YouTube videos for the specific pattern you need to understand, and a documentation culture that produces dense technical references rather than worked examples. The fortran-lang.org Learn section and Curcic's "Modern Fortran: Style and Usage" (2020) have materially improved this, but the gap to Python or Java documentation ecosystems remains wide.

**Salary and market data** from ZipRecruiter reports an average of $102,500 for US Fortran developers as of February 2026 [ZIPRECRUITER-FORTRAN], with senior roles in national laboratories and defense contractors commanding $165,000–$370,000 [6FIGR-FORTRAN]. These numbers reflect scarcity premium rather than language popularity: there are fewer Fortran developers than there is demand, particularly for those who combine numerical domain expertise with software engineering skills. This is genuinely favorable for practitioners, but the job market is narrow — concentrated in aerospace (Lockheed Martin, Boeing, Raytheon), national laboratories (DOE: ORNL, ANL, LLNL, Sandia), and climate/weather agencies — and not growing in breadth [RESEARCH-BRIEF-DX].

---

## 9. Performance Characteristics

Performance is the one area where Fortran's production reputation is fully warranted and where the practitioner can provide the clearest endorsement. For compute-bound numerical kernels on modern hardware, well-optimized Fortran code is competitive with optimally written C or C++ and frequently outperforms Python (even NumPy-based Python) for the same workload.

The mechanism for this performance is important to understand: it is not magic. Fortran produces fast code on numerical workloads for identifiable reasons that the practitioner can exploit deliberately:

1. **Arrays are not pointers.** The Fortran standard restricts how arrays can alias each other. A Fortran compiler can assume that two `REAL64` arrays accessed in the same loop do not overlap in memory unless they are provably the same array. C compilers cannot make this assumption without `restrict`, which programmers must add explicitly and which is often omitted. This aliasing freedom enables aggressive register allocation and loop transformations [FORTRAN-BEST-PRACTICES].

2. **INTENT declarations are optimization opportunities.** An `INTENT(IN)` dummy argument tells the compiler that the routine does not modify the argument; combined with the aliasing model, this enables inlining and hoisting that C compilers cannot perform without explicit `const`.

3. **ELEMENTAL and array intrinsics map directly to SIMD.** The `SUM`, `PRODUCT`, `DOT_PRODUCT`, and `MATMUL` intrinsics, and user-defined ELEMENTAL functions, express the exact computation in a form that modern vectorizing compilers can target directly to SSE, AVX-512, or SVE instructions. A hand-written scalar loop over the same data may vectorize as well, but the intrinsic form is more reliably vectorized across compiler versions and optimization levels.

4. **Column-major storage matches BLAS/LAPACK access patterns.** Fortran's column-major layout means that LAPACK's internal access patterns (which traverse columns of matrices) are cache-aligned. This is not coincidental — BLAS and LAPACK were written in Fortran specifically to exploit this [BLAS-LAPACK-REF].

The **production tax** for performance is real, however. Achieving peak performance requires understanding compiler optimization flags in a way that few mainstream languages demand. The difference between `-O0` (debug builds) and `-O3 -march=native -funroll-loops` (aggressively optimized production builds) can be a 2–5× speedup for numerical kernels [RESEARCH-BRIEF-PERF]. Running code compiled with the wrong flags and wondering why performance is disappointing is a common new-practitioner mistake. The flags are not self-documenting; the compiler's optimization report (`-fopt-info` in GFortran, `-qopt-report` in ifx) is verbose and requires learning to read.

**Intel ifx deprecating and discontinuing ifort** (classic compiler, discontinued in the oneAPI 2025 release [INTEL-IFX-2025]) is a live operational concern for practitioners. Many HPC centers have codebases tuned specifically for ifort's optimization passes — auto-vectorization heuristics, loop fusion behavior, and profile-guided optimization flows that were developed and tested against ifort over years. Migrating to ifx (which uses an LLVM backend and makes different optimization choices) or to GFortran requires retesting performance characteristics and may require tuning. This is not a hypothetical future concern — it is an active migration that many national laboratory and aerospace development teams are managing in 2025–2026.

**LLVM Flang's performance** is still catching up [LINARO-FLANG], running approximately 23% slower than GFortran at compile time and producing competitive but not always superior runtime code. For production use, GFortran and ifx remain the performance-validated choices; Flang is the future but requires validation on specific workloads before being trusted in production. The teams backing it — NVIDIA, AMD, Arm, and DOE national laboratories — are credible, and the LLVM infrastructure should eventually surpass GFortran's code quality, but "eventually" is not a production deployment criterion.

**GPU acceleration** has delivered real performance for codes that have invested in OpenACC or DO CONCURRENT with NVIDIA nvfortran. WRF GPU runs reported by NVIDIA show meaningful speedups on A100 hardware for numerically intensive physics parameterizations [NVIDIA-HPC-SDK]. The practitioner caveat: achieving these speedups requires careful management of data movement between CPU and GPU memory, which in Fortran code means explicit `!$ACC DATA` directives or `!$OMP TARGET DATA` regions. The conceptual model for what data lives where is the practitioner's primary cognitive burden in GPU Fortran, and diagnosing performance problems (is it compute-bound or data-transfer-bound?) requires profiling tools that HPC practitioners are beginning to learn but that are not as accessible as gprof or Valgrind.

---

## 10. Interoperability

Fortran's interoperability story begins and ends with `ISO_C_BINDING`, the Fortran 2003 module that standardized the interface between Fortran and C [RESEARCH-BRIEF-TECH]. Before ISO_C_BINDING, calling C from Fortran or vice versa was a compiler-specific exercise in convention-matching — name mangling differences, calling convention differences, and structure layout differences required careful hand-tuning per compiler. ISO_C_BINDING makes this explicit and portable: C types are mapped to Fortran types (C_INT, C_DOUBLE, C_PTR), C function signatures are expressed as Fortran interface blocks, and calling conventions align correctly.

In practice, ISO_C_BINDING has made Fortran a viable participant in mixed-language HPC codebases. The major Fortran libraries (FFTW, NetCDF, HDF5) provide Fortran 2003-compatible interfaces built on ISO_C_BINDING [RESEARCH-BRIEF-ECOSYSTEM]. This means the practitioner can use C's rich ecosystem through Fortran wrappers without dropping to raw convention-matching. The pattern is workable, and the large climate and weather codes that interface with dozens of C libraries depend on it functioning correctly. It does.

The persistent **column-major / row-major footgun** at the C boundary deserves repeating here because it is the most common interoperability bug. When passing a multidimensional array from Fortran to a C function (or from a C caller to a Fortran subroutine), the logical matrix that one side sees as row-organized is physical-memory-transposed on the other side. ISO_C_BINDING does not help here — it handles type mapping, not semantic interpretation of array layout. The correct fix is either (a) passing 1D arrays and handling indexing manually, (b) transposing explicitly before passing, or (c) documenting the expected layout convention precisely. All three add burden to every Fortran/C interface point.

**Python interoperability** is increasingly important as the broader scientific computing community has shifted heavily toward Python for data analysis, visualization, and workflow orchestration. The standard tool is `f2py` (part of NumPy), which generates Python wrappers for Fortran routines. f2py works reliably for simple cases — subroutines with scalar and array arguments, basic INTENT declarations — and fails or requires hand-annotation for complex cases involving derived types, allocatable arguments, or optional arguments. The practitioner who has a validated Fortran numerical kernel and wants to call it from a Python driver script can typically make f2py work, with some effort. The practitioner who wants bidirectional interoperability, Python objects passed to Fortran, or complex Fortran types exposed to Python has a much harder time. Cffi-based wrappers are an alternative but require more manual effort.

**MPI's interoperability story** is Fortran's best: the Fortran MPI bindings are mature, well-documented, and used at the largest scale in production [RESEARCH-BRIEF-TECH]. A Fortran MPI program can communicate with C MPI processes in the same communicator (MPI is language-agnostic at the wire level). This enables mixed-language codebases where, for instance, a preprocessing stage in Python launches an MPI job that mixes Fortran physics kernels with C++ I/O routines. This kind of polyglot HPC job is increasingly common at scale.

**Cross-compilation** for HPC targets is mostly the compiler's concern — the practitioner invokes the platform-specific compiler (Cray compiler on Cray machines, NVIDIA nvfortran on GPU clusters, ifx on Intel clusters) rather than writing cross-compilation infrastructure. This is simpler than embedded-systems cross-compilation but means that a code tested on a developer's workstation with GFortran may have behavior differences on the production cluster with a different compiler. Compiler-specific behavior around IEEE exception handling, extended precision intermediate results, and optimization-dependent behavior are known sources of portability bugs.

---

## 11. Governance and Evolution

Fortran's governance model is the slowest-moving but most durable in the language landscape. The J3/WG5 committee structure — J3 as the US national body, WG5 as the ISO international working group — has produced a standard revision approximately every five years [J3-HOME] [WG5-HOME]. The Fortran 2023 standard, published November 2023, is the most recent. The committee process is consensus-based with no BDFL, no single corporate controller, and a mandate to maintain backward compatibility as a primary constraint [RESEARCH-BRIEF-GOV].

The practitioner's experience with this governance model is mixed. On the positive side: stability and backward compatibility mean that code written in 1985 compiles today. The organizational stakeholders (Intel, NVIDIA, AMD, Arm, DOE national laboratories) have genuine investment in compiler quality and standard compliance. The standard is technically rigorous and unambiguous in ways that governance-by-corporate-fiat often is not. WG5's careful handling of feature removals — declaring features obsolescent for one or two standards before removing them — means that even the removal of COMMON and EQUIVALENCE from Fortran 2023 comes with compiler compatibility extensions that will keep legacy code compiling indefinitely.

On the negative side: **five-year standards cycles are very slow** for a language competing with Python's annual feature releases, Rust's six-week releases, and the general pace of modern language evolution. The template/generics feature that the Fortran community urgently needs has been in discussion for years and is not in Fortran 2023 [J3-HOME]. The post-2023 standard (informally "Fortran 202Y" or Fortran 2028) is under development, but "under development" in J3/WG5 terms means many meeting cycles of proposal, revision, formal ballot, and ISO publication before any compiler implements it. A practitioner who needs generics today uses workarounds today; the language is not coming to rescue them in any near-term timeframe.

The **Intel ifort discontinuation** in oneAPI 2025 [INTEL-IFX-2025] is a case study in how vendor decisions affect the governance landscape. ifort was for decades the de facto standard for production HPC Fortran, especially on Intel architectures. Intel's decision to discontinue it in favor of ifx (LLVM-based) forces the entire ecosystem that relied on ifort behavior to validate against ifx. Intel made this decision unilaterally — the committee had no mechanism to prevent or slow it. The community response has been largely practical: validation efforts, documentation of ifx differences, and acceptance. But it illustrates that despite the committee governance model, major vendors' product decisions are outside committee control.

The **fortran-lang community** (founded 2020) is an encouraging development from the practitioner's perspective precisely because it operates outside the standards committee. While J3/WG5 governs the language specification, fortran-lang governs the practical tooling: fpm, stdlib, fortls, the fortran-lang.org website and Learn section [CURCIC-MEDIUM-2021] [ARXIV-TOOLING-2021]. This separation of concerns — standards committee handles specification, community handles tooling — has produced faster practical improvement than standards revisions alone could have. But fortran-lang is a volunteer organization without sustainable institutional funding, and the velocity of improvements depends on contributors who are often employed primarily as scientists or software engineers with Fortran as a side concern rather than their primary mission.

The **LLVM Flang graduation** (renamed from `flang-new` in LLVM 20, March 2025 [LLVM-FLANG-2025]) backed by NVIDIA, AMD, Arm, and DOE national laboratories is the most significant governance development in recent years. It represents industry consensus that a viable open-source LLVM-based Fortran compiler is strategically important enough to fund. For the practitioner, this is the best long-term insurance against the scenario where GFortran development stagnates and there is no open-source alternative. The short-term practitioner reality is that Flang is not yet a drop-in replacement for GFortran or ifx for production use — the performance gap and missing feature coverage require validation — but the trajectory is clear.

---

## 12. Synthesis and Assessment

### Greatest Strengths

**Numerical performance that has never been surpassed for its target domain.** The original bet made in 1954 — that compiled high-level code could match hand-assembly for numerical computation — was won [IBM-HISTORY-FORTRAN], and the subsequent seven decades of compiler development have deepened the advantage. Fortran's array intrinsics, its aliasing model, its memory layout predictability, and its absence of garbage collection make it the reference implementation point for numerical performance. BLAS and LAPACK are still Fortran, still the reference against which all numerical linear algebra implementations are measured, still the foundation on which NumPy, SciPy, MATLAB, and R compute [BLAS-LAPACK-REF]. That is 68 years of correct and fast numerical computation at the foundation of all scientific computing. The practitioner inherits both the performance and the validated correctness.

**Array semantics as a first-class language design.** Fortran's array model — where arrays are typed, ranked, bounded, and operable as units — is the most expressive general array model in any production language. Whole-array arithmetic, array sections, elemental functions, and array intrinsics compose naturally in a way that makes numerical algorithms expressible close to their mathematical form. This is not a small advantage: numerical code that is readable at the domain level is maintainable code, and maintainability is the dominant cost driver in long-lived scientific software.

**Backward compatibility as survival.** The ability to run FORTRAN 77 code with a modern compiler — or to incrementally modernize it one subroutine at a time while preserving the rest — has enabled the scientific community's enormous investment in validated Fortran code to compound rather than reset with each language version. This is the mechanism that explains Fortran's 70-year lifespan. The practitioner who needs to build on 1985 atmospheric physics code can do so without rewriting it; the correctness validation encoded in that code's decades of production use transfers forward.

**Compiler ecosystem with genuine institutional backing.** The combination of GFortran (free, open-source, nearly universal), Intel ifx (LLVM-based, performance-tuned for Intel hardware), NVIDIA nvfortran (GPU acceleration via OpenACC), and LLVM Flang (emerging, backed by major vendors and DOE national laboratories) represents the strongest set of compiler options Fortran has had since the 1980s commercial compiler era [RESEARCH-BRIEF-COMPILERS]. The practitioner is not dependent on a single vendor's survival.

### Greatest Weaknesses

**The ecosystem deficit is the primary practical barrier.** A language is its ecosystem, and Fortran's ecosystem is a numerical island. JSON parsing, HTTP, databases, logging, testing frameworks, data serialization, command-line argument handling, cryptography — all of these require either calling C libraries via ISO_C_BINDING or writing the functionality from scratch. The fortran-lang/stdlib project is chipping away at the gap, but the honest comparison to Python's 550,000-package PyPI ecosystem is that Fortran is not close, will not be close in any near-term timeframe, and the community's volunteer resources are not sufficient to close it. For numerical computation alone, this does not matter. For any realistic production system that includes numerical computation plus operational infrastructure, it means Fortran is always a component language in a larger system, with significant integration cost at every boundary.

**The FORTRAN 77 legacy imposes a permanent cognitive tax.** The volume of fixed-form, implicitly-typed, COMMON-block-using, GOTO-structured code that production Fortran practitioners must read and maintain is very large and is not shrinking quickly. Automated migration tools are limited; the semantic understanding required to safely modernize a 30,000-line FORTRAN 77 model exceeds what current AI tools reliably provide. The practitioner who is responsible for a legacy HPC codebase is not just maintaining Fortran — they are maintaining a historical artifact that requires specialized archaeological skills that are difficult to teach and impossible to automate.

**Error handling ergonomics are inadequate for production systems.** The combination of optional STAT/IOSTAT checking, no exception propagation mechanism, no standardized error type, and a culture of error-ignoring legacy code means that production Fortran systems are routinely operating without the error instrumentation that would be considered minimal in Java, Python, or Rust codebases of equivalent complexity. The practitioner working on a production HPC code must add error instrumentation defensively and cannot assume that anything below them in the call stack has instrumented its error paths.

**The developer community is small, aging, and geographically concentrated.** Stack Overflow coverage is thin. Tutorial resources are improving but remain sparse compared to mainstream languages. The experienced Fortran practitioner population is concentrated in national laboratories, aerospace firms, and academic HPC centers — a narrow labor market that makes hiring difficult and onboarding slow. The demographic aging problem is real: the most experienced Fortran practitioners are disproportionately senior engineers approaching retirement, and knowledge transfer to younger practitioners is not systematic [RESEARCH-BRIEF-DX].

### Lessons for Language Design

**1. Domain excellence can sustain a language across generational technological shifts — if the domain itself persists.** Fortran has survived COBOL's decline, the rise of object-oriented programming, the scripting language era, the cloud era, and the AI era because the domain it serves — numerical computation — has not gone away and has in fact grown. A language that achieves genuine superiority in a durable domain builds an institutional and knowledge investment that resists displacement even when better general-purpose alternatives emerge. Language designers choosing a focus should ask whether the target domain is permanent: if it is, domain-specific optimization is a long-term investment; if it is not, language survival depends on general utility.

**2. Backward compatibility is survival insurance with a compounding maintenance cost.** Fortran's decision to standardize FORTRAN 77 idioms in the 1966 ASA standard, and to maintain those idioms through every subsequent revision, is the primary reason 70-year-old code compiles today. That is genuinely remarkable. The cost is the permanent presence of IMPLICIT typing, COMMON blocks, and EQUIVALENCE in the language specification, the cognitive burden of legacy idioms for every practitioner who maintains inherited code, and the constraint these features impose on modernization. Language designers must weigh compatibility as a design goal against the accumulated weight it creates: the right answer is probably to commit fully to compatibility (as Fortran did) or to make deliberate, well-supported breaking changes (as Python did at Python 2→3), rather than half-measures that preserve surface syntax while breaking underlying semantics.

**3. Optional error checking creates systemic quality debt across entire ecosystems.** Fortran's IMPLICIT typing (suppressible via `IMPLICIT NONE`) and optional STAT/IOSTAT error checking are both instances of the same design error: making correctness mechanisms opt-in rather than opt-out means the default code is incorrect code, and correcting it requires intentional action that a large fraction of practitioners, particularly in deadline-driven scientific computing contexts, will not take. The consequence is not individual bugs but a systemic ecosystem-wide quality deficit where the vast majority of production code has implicit error-suppression built in. Language designers should treat "secure by default" and "correct by default" as first-class design constraints: the effort to override a default is far less than the effort to retrofit a convention across a million lines of existing code.

**4. A language without a standard library is limited to one ecosystem.** The absence of a rich standard library in Fortran forced the scientific computing community to build BLAS, LAPACK, NetCDF, and HDF5 as independent C libraries with Fortran bindings, rather than as a cohesive in-language ecosystem. The consequence is that Fortran's practical ecosystem is C's ecosystem accessed through an FFI layer — workable but not a native experience. Language designers should consider that standard library scope defines the boundary of what practitioners can do without crossing ecosystem boundaries; every gap in the standard library is an ISO_C_BINDING call waiting to happen.

**5. The "production tax" of missing tooling can exceed the value of language-level design quality.** Fortran's type system and performance model are excellent for their domain. Its tooling as recently as 2019 was inadequate for modern development practices: no package manager, no language server, inconsistent build systems, thin testing frameworks. The 2021 fortran-lang tooling paper [ARXIV-TOOLING-2021] documented this explicitly. The lesson is that a language can be technically excellent and practically unusable simultaneously, and that the decision to use a language is made at the tooling level more often than at the specification level. Language designers — and especially language stewards — must treat tooling as a first-class investment equal in importance to specification development.

**6. Naming and identity matter for adoption.** FORTRAN 77's fixed-form source, uppercase identifiers, and punch-card-column format created an aesthetic barrier to new practitioners that the language spec itself does not impose — modern Fortran is free-form, lowercase-friendly, and syntactically clean. But perception lags reality by decades, and many practitioners encountering Fortran for the first time in 2026 form their initial impression from legacy code rather than modern code. The name "Fortran" carries a cognitive overhead of "obsolete" that the technical quality of modern Fortran does not warrant. Language stewards should invest in making the gap between first-impression aesthetics and production reality as small as possible; every year that a modern practitioner bounces off legacy code before reaching modern idioms is a potential convert lost.

**7. Multiple compiler implementations with organizational backing are a strategic language asset.** The combination of GFortran, Intel ifx, NVIDIA nvfortran, and LLVM Flang means that Fortran does not have a single-vendor failure mode. If Intel withdrew from Fortran tomorrow, GFortran and Flang would sustain the ecosystem. If NVIDIA's HPC business contracted, Intel and AMD compilers would cover the gap. This diversity of implementation — even if it creates feature inconsistency and compatibility testing burden — is fundamentally different from the situation of a language backed by a single organization whose strategic interests may shift. Language designers and stewards should cultivate multiple independent implementations as insurance against organizational risk.

**8. Community-driven tooling can move faster than standards committee governance, but requires sustainable funding.** The fortran-lang community (2020–present) has produced more practical improvements to the Fortran development experience in five years than the J3/WG5 standards process has produced in fifteen. fpm, fortls, stdlib, and fortran-lang.org are practical tools that practitioners use today, built by volunteers outside the standards process. The risk is that volunteer community projects are vulnerable to contributor burnout and funding gaps. The lesson: language stewardship should separate the specification process (which benefits from slow, careful consensus) from the tooling and ecosystem development process (which benefits from rapid iteration and practical feedback). But the tooling effort requires institutional funding to be sustainable — it cannot be sustained as volunteer work alone at scale.

### Dissenting Views

**On legacy burden:** One community perspective holds that the presence of legacy FORTRAN 77 code in production is a feature rather than a defect — it represents validated scientific software that has been used correctly for decades, and its inaccessibility to newcomers is a temporary problem that better documentation and AI-assisted code explanation will address. The practitioner counterpoint is that the maintenance burden of code that cannot be refactored safely, cannot be unit-tested in isolation, and cannot be understood by new team members is an ongoing institutional liability that compounds, not one that documentation will dissolve.

**On tooling expectations:** Some practitioners argue that HPC development has different norms than application development — that the "just write a Makefile" culture is appropriate for its context, that scientists who write numerical code do not need the development ergonomics of web developers, and that fpm is a solution to a problem that HPC practitioners did not identify as urgent. The practitioner counterpoint is that this attitude systematically excludes competent software engineers from contributing to scientific computing codebases, limits the talent pool for scientific software development, and ultimately produces lower-quality software than it would if modern tooling norms were applied.

**On performance claims:** The claim that Fortran is "the fastest language" or "uniquely fast" oversimplifies the comparison. Equivalent C code with proper `restrict` annotations and SIMD intrinsics achieves the same performance. Modern C++ with expression templates matches Fortran's numerical expressiveness with comparable performance. The honest claim is that Fortran's *defaults* and *idioms* produce fast numerical code more reliably than C's defaults and idioms — not that Fortran code is inherently faster than the theoretically optimal implementation in any other language.

---

## References

[IBM-HISTORY-FORTRAN] IBM. "Fortran." IBM History. https://www.ibm.com/history/fortran. Accessed 2026-02-28.

[BACKUS-HISTORY-1978] Backus, John. "The History of Fortran I, II, and III." ACM SIGPLAN History of Programming Languages, 1978.

[ISO-FORTRAN-2023] ISO/IEC. "ISO/IEC 1539-1:2023 — Programming languages — Fortran — Part 1: Base language." ISO, November 2023. https://www.iso.org/standard/82170.html.

[WG5-F2023] Reid, John. "ISO/IEC JTC1/SC22/WG5 N2212: The new features of Fortran 2023." WG5 Fortran. https://wg5-fortran.org/N2201-N2250/N2212.pdf.

[J3-HOME] INCITS/Fortran (J3). "J3 Fortran — Home." https://j3-fortran.org/.

[WG5-HOME] ISO/IEC JTC1/SC22/WG5. "WG5 Fortran Standards Home." https://wg5-fortran.org/.

[ARXIV-TOOLING-2021] Čertík, Ondřej et al. "Toward Modern Fortran Tooling and a Thriving Developer Community." arXiv:2109.07382, September 2021. https://arxiv.org/abs/2109.07382.

[CURCIC-MEDIUM-2021] Curcic, Milan. "First year of Fortran-lang." Medium / Modern Fortran. https://medium.com/modern-fortran/first-year-of-fortran-lang-d8796bfa0067.

[FORTRAN-LANG-DERIVED] fortran-lang.org. "Derived Types — Fortran Programming Language." https://fortran-lang.org/learn/quickstart/derived_types/.

[FORTRAN-LANG-ALLOC] fortran-lang.org. "Allocatable Arrays — Fortran Programming Language." https://fortran-lang.org/learn/best_practices/allocatable_arrays/.

[STDLIB-GITHUB] GitHub. "fortran-lang/stdlib: Fortran Standard Library." https://github.com/fortran-lang/stdlib.

[STDLIB-1000-STARS] Fortran Discourse. "The Fortran stdlib project has garnered over 1000 stars on GitHub!" June 2024. https://fortran-lang.discourse.group/t/the-fortran-stdlib-project-has-garnered-over-1000-stars-on-github/8244.

[FPM-HOME] Fortran Package Manager. https://fpm.fortran-lang.org/.

[FPM-2024] Fortran Package Manager. "Posted in 2024 — Fortran Package Manager." https://fpm.fortran-lang.org/news/2024.html.

[VSCODE-FORTRAN] fortran-lang. "fortran-lang/vscode-fortran-support: Fortran language support for Visual Studio Code." GitHub. https://github.com/fortran-lang/vscode-fortran-support.

[LLVM-FLANG-2025] LLVM Project Blog. "LLVM Fortran Levels Up: Goodbye flang-new, Hello flang!" March 11, 2025. https://blog.llvm.org/posts/2025-03-11-flang-new/.

[LINARO-FLANG] Linaro. "Comparing LLVM Flang with other Fortran compilers." https://www.linaro.org/blog/comparing-llvm-flang-with-other-fortran-compilers/.

[INTEL-IFX-2025] Intel. "Intel® Fortran Compiler for oneAPI Release Notes 2025." https://www.intel.com/content/www/us/en/developer/articles/release-notes/fortran-compiler/2025.html.

[INTEL-COARRAY] Intel. "Use Coarrays." Intel Fortran Compiler Developer Guide and Reference, 2023. https://www.intel.com/content/www/us/en/docs/fortran-compiler/developer-guide-reference/2023-0/use-coarrays.html.

[NVIDIA-HPC-SDK] NVIDIA. "NVIDIA HPC Fortran, C and C++ Compilers with OpenACC." https://developer.nvidia.com/hpc-compilers.

[NVIDIA-DO-CONCURRENT] NVIDIA Technical Blog. "Accelerating Fortran DO CONCURRENT with GPUs and the NVIDIA HPC SDK." https://developer.nvidia.com/blog/accelerating-fortran-do-concurrent-with-gpus-and-the-nvidia-hpc-sdk/.

[COARRAYS-SOURCEFORGE] Coarrays.sourceforge.io. "Parallel programming with Fortran 2008 and 2018 coarrays." https://coarrays.sourceforge.io/doc.html.

[NASA-FORTRAN-2015] NASA Advanced Supercomputing Division. "NASA and the Future of Fortran." April 28, 2015. https://www.nas.nasa.gov/pubs/ams/2015/04-28-15.html.

[BLAS-LAPACK-REF] UCSC AMS 209. "External Libraries for Scientific Computing." https://users.soe.ucsc.edu/~dongwook/wp-content/uploads/2016/ams209/lectureNote/_build/html/chapters/chapt02/ch02_fortran_blas_lapack.html.

[WRF-FORTRAN-MEDIUM] partee.io. "Why are Climate models written in programming languages from 1950?" February 2021. https://partee.io/2021/02/21/climate-model-response/.

[CLIMATE-MODELS-FORTRAN] Medium / Julius Uy. "Fortran in Weather and Climate Research: Migration Challenges, Costs, and Strategic Decisions." https://medium.com/@julius.uy/fortran-in-weather-and-climate-research-migration-challenges-costs-and-strategic-decisions-66c985bae4a2.

[FORTRANWIKI-STANDARDS] Fortran Wiki. "Standards." https://fortranwiki.org/fortran/show/Standards.

[FORTRAN-DISCOURSE] Fortran Discourse Community. https://fortran-lang.discourse.group/.

[FORTRAN-DISCOURSE-BOUNDS] Fortran Discourse. "Array Bounds Checking - Standard Behavior?" https://fortran-lang.discourse.group/t/array-bounds-checking-standard-behavior/5782.

[FORTRAN-BEST-PRACTICES] fortran90.org. "Fortran Best Practices." https://www.fortran90.org/src/best-practices.html.

[FORTRAN-WIKIBOOKS-ERR] Wikibooks. "Fortran/error handling." https://en.wikibooks.org/wiki/Fortran/error_handling.

[ERRSTAT-GITHUB] GitHub. "degawa/errstat: error status and message handling library for Modern Fortran." https://github.com/degawa/errstat.

[MEMORY-SAFETY-WIKI] Wikipedia. "Memory safety." https://en.wikipedia.org/wiki/Memory_safety.

[PHRACK-FORTRAN] Phrack Magazine. "Exploiting Memory Corruptions in Fortran Programs Under Unix." Phrack Issue 67. http://phrack.org/issues/67/11.html.

[FORTRANUK-MEMSAFE] Fortran UK. "Is Fortran 'Memory Safe'?" https://fortran.uk/isfortranmemorysafe/.

[ZIPRECRUITER-FORTRAN] ZipRecruiter. "Salary: Fortran Developer (February, 2026) United States." https://www.ziprecruiter.com/Salaries/Fortran-Developer-Salary.

[6FIGR-FORTRAN] 6figr. "Fortran Salaries 2026." https://6figr.com/us/salary/fortran--s.

[RESEARCH-BRIEF-TECH] Penultima Research Repository. "Fortran — Research Brief: Technical Characteristics." 2026-02-28. [research/tier1/fortran/research-brief.md].

[RESEARCH-BRIEF-ECOSYSTEM] Penultima Research Repository. "Fortran — Research Brief: Ecosystem Snapshot." 2026-02-28. [research/tier1/fortran/research-brief.md].

[RESEARCH-BRIEF-SECURITY] Penultima Research Repository. "Fortran — Research Brief: Security Data." 2026-02-28. [research/tier1/fortran/research-brief.md].

[RESEARCH-BRIEF-DX] Penultima Research Repository. "Fortran — Research Brief: Developer Experience Data." 2026-02-28. [research/tier1/fortran/research-brief.md].

[RESEARCH-BRIEF-PERF] Penultima Research Repository. "Fortran — Research Brief: Performance Data." 2026-02-28. [research/tier1/fortran/research-brief.md].

[RESEARCH-BRIEF-GOV] Penultima Research Repository. "Fortran — Research Brief: Governance." 2026-02-28. [research/tier1/fortran/research-brief.md].

[RESEARCH-BRIEF-COMPILERS] Penultima Research Repository. "Fortran — Research Brief: Major Compilers." 2026-02-28. [research/tier1/fortran/research-brief.md].
